---
layout: post
title: Getting Started with Scrapy
---

## Getting Started with Scrapy

This post is a quick overview of getting started with _[Scrapy](https://scrapy.org/)_, an open source Python-based web scraping tool that is quick to install from the shell:

```shell
pip install Scrapy
```

or, via Anaconda:

```shell
conda install -c conda-forge scrapy
```

_Scrapy_ provides a handy shell for testing out bits of code before starting your project. Simply type ``scrapy shell`` from your preferred shell. We'll start by using the shell to run a crawler and look at the response, then attempt to find pertinent DOM elements to scrape. To demonstrate the usefulness of Scrapy, we're going to scrape some world markets data from [Google Finance](https://finance.google.com/finance):

![World Markets](https://github.com/strongdan/blog/blob/gh-pages/assets/world_markets.png)

Typing `scrapy shell` brings up a bunch of text, which you're not expected to read, and the shell prompt:

![Scrapy Shell](https://github.com/strongdan/blog/blob/gh-pages/assets/scrapy_shell.png)

From here, you can make requests of web pages using the *fetch* method with your preferred web URL. For this tutorial, we'll fetch from Google Finance, like so: `fetch(https://finance.google.com/finance)`

### Starting a New Project

This project follows the _Scrapy_ [documentation](https://docs.scrapy.org/en/latest/) tutorial for setting up and running a _Scrapy_ project, writing a spider to crawl a site, and exporting the scraped data. Starting a new project is as simple as typing ``scrapy startproject [project name]`` in the shell. For the tutorial, we'll type ``scrapy startproject tutorial``. This will create a basic tutorial directory structure:

```python
tutorial/
    scrapy.cfg            # deploy configuration file

    tutorial/             # project's Python module, you'll import your code from here
        __init__.py

        items.py          # project items definition file

        pipelines.py      # project pipelines file

        settings.py       # project settings file

        spiders/          # a directory where you'll later put your spiders
            __init__.py
```

https://www.analyticsvidhya.com/blog/2017/07/web-scraping-in-python-using-scrapy/

https://bigishdata.com/2017/05/11/general-tips-for-web-scraping-with-python/

### Links
[Scrapy Documentation](https://docs.scrapy.org/en/latest/)
