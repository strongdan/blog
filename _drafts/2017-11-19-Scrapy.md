---
layout: post
title: Getting Started with Scrapy
---

## Getting Started with Scrapy

[Scrapy](https://scrapy.org/) is an open source Python-based web scraping tool that is quick to install from the shell:

```shell
pip install Scrapy
```

or, via Anaconda:

```shell
conda install -c conda-forge scrapy
```

This post is a quick review of the [documentation's](https://docs.scrapy.org/en/latest/) tutorial for setting up and running a Scrapy project, writing a spider to crawl a site, and exporting the scraped data. 

Scrapy provides a handy shell for testing out bits of code before starting your project. Simply type ``scrapy shell`` from your preferred shell. We'll start by using the shell to run a crawler and look at the response, then attempt to find pertinent DOM elements to scrape. 

Starting a new project is as simple as typing ``scrapy startproject [project name]`` in the shell. For the tutorial, we'll type ``scrapy startproject tutorial``. This will create a basic tutorial directory structure:

```python
tutorial/
    scrapy.cfg            # deploy configuration file

    tutorial/             # project's Python module, you'll import your code from here
        __init__.py

        items.py          # project items definition file

        pipelines.py      # project pipelines file

        settings.py       # project settings file

        spiders/          # a directory where you'll later put your spiders
            __init__.py
```

https://www.analyticsvidhya.com/blog/2017/07/web-scraping-in-python-using-scrapy/

https://bigishdata.com/2017/05/11/general-tips-for-web-scraping-with-python/

### Links
[Scrapy Documentation](https://docs.scrapy.org/en/latest/)
